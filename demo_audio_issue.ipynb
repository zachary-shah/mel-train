{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zachary/miniconda3/envs/mel-gen/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from spleeter.separator import Separator\n",
    "from spleeter.audio.adapter import AudioAdapter\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import librosa\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "import pydub\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "\n",
    "from utils import spleeter_utils\n",
    "\n",
    "import cv2\n",
    "\n",
    "from riffusion.spectrogram_image_converter import SpectrogramImageConverter\n",
    "from riffusion.spectrogram_converter import SpectrogramConverter\n",
    "from riffusion.spectrogram_params import SpectrogramParams\n",
    "\n",
    "#sample_audio_path = \"pop.00027_seg4_full.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_converter = SpectrogramImageConverter(SpectrogramParams(sample_rate=44100, min_frequency=0, max_frequency=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225351, 1)\n",
      "(225351, 1)\n",
      "225351\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "audio_loader = AudioAdapter.default()\n",
    "waveform, _ = audio_loader.load(sample_audio_path, sample_rate=44100)\n",
    "# print(waveform, type(waveform))\n",
    "print(np.shape(np.int64(waveform / (np.max(np.abs(waveform))) * (2**15-1))))\n",
    "print(np.shape(waveform))\n",
    "byte_count = (np.int8(waveform / (np.max(np.abs(waveform))) * (2**15-1))).copy().tobytes()\n",
    "print(len(byte_count))\n",
    "print(waveform.dtype.itemsize)\n",
    "waveform =  np.int16(waveform / (np.max(np.abs(waveform))) * (2**15-1))\n",
    "song = pydub.AudioSegment(\n",
    "    waveform.tobytes(),\n",
    "    frame_rate=44100,\n",
    "    sample_width=waveform.dtype.itemsize, \n",
    "    channels=1\n",
    ")\n",
    "\n",
    "# song = pydub.AudioSegment.from_file(sample_audio_path, sr=44100)\n",
    "\n",
    "out_img = img_converter.spectrogram_image_from_audio(song)\n",
    "out_img.save(\"temp_spec.jpg\", exif=out_img.getexif())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='temp_wav_good_edges.wav'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_filepath = \"train-150l200h/source/pop.00027_seg4.jpg\"\n",
    "\n",
    "recon_img =  Image.open(recon_filepath).convert(\"RGB\")\n",
    "\n",
    "img_converter_to_audio = SpectrogramImageConverter(SpectrogramParams(sample_rate=44100, min_frequency=0, max_frequency=10000))\n",
    "\n",
    "out_audio_recon = img_converter_to_audio.audio_from_spectrogram_image(recon_img, apply_filters=True).set_channels(2)\n",
    "out_audio_recon.export(\"temp_wav_good_edges.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\18nee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llvmlite\\llvmpy\\__init__.py:3: UserWarning: The module `llvmlite.llvmpy` is deprecated and will be removed in the future.\n",
      "  warnings.warn(\n",
      "c:\\Users\\18nee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llvmlite\\llvmpy\\core.py:8: UserWarning: The module `llvmlite.llvmpy.core` is deprecated and will be removed in the future. Equivalent functionality is provided by `llvmlite.ir`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\18nee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\llvmlite\\llvmpy\\passes.py:17: UserWarning: The module `llvmlite.llvmpy.passes` is deprecated and will be removed in the future. If you are using this code, it should be inlined into your own project.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 661794) <class 'numpy.matrix'>\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "WARNING:tensorflow:From c:\\Users\\18nee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m spleeter_utils\n\u001b[0;32m      2\u001b[0m sample_audio_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw-audio/blues.00000.wav\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m info \u001b[39m=\u001b[39m spleeter_utils\u001b[39m.\u001b[39;49mseparate_audio(sample_audio_path, fs\u001b[39m=\u001b[39;49m\u001b[39m44100\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\18nee\\Desktop\\stanford\\wi22\\EE269\\mel-train\\utils\\spleeter_utils.py:44\u001b[0m, in \u001b[0;36mseparate_audio\u001b[1;34m(inp_audio_path, fs, stem_num)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mshape(waveform), \u001b[39mtype\u001b[39m(waveform), flush\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     43\u001b[0m separator \u001b[39m=\u001b[39m Separator(\u001b[39m\"\u001b[39m\u001b[39mspleeter:2stems\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m pred_audio_stem \u001b[39m=\u001b[39m separator\u001b[39m.\u001b[39;49mseparate(waveform)\n\u001b[0;32m     45\u001b[0m pred_audio_stem[\u001b[39m\"\u001b[39m\u001b[39mfull_audio\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(waveform)\n\u001b[0;32m     47\u001b[0m pred_audio_stem[\u001b[39m\"\u001b[39m\u001b[39maccompaniment\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mto_mono(pred_audio_stem[\u001b[39m\"\u001b[39m\u001b[39maccompaniment\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mT)\n",
      "File \u001b[1;32mc:\\Users\\18nee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spleeter\\separator.py:321\u001b[0m, in \u001b[0;36mSeparator.separate\u001b[1;34m(self, waveform, audio_descriptor)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_separate_tensorflow(waveform, audio_descriptor)\n\u001b[0;32m    320\u001b[0m \u001b[39melif\u001b[39;00m backend \u001b[39m==\u001b[39m STFTBackend\u001b[39m.\u001b[39mLIBROSA:\n\u001b[1;32m--> 321\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_separate_librosa(waveform, audio_descriptor)\n\u001b[0;32m    322\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported STFT backend \u001b[39m\u001b[39m{\u001b[39;00mbackend\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\18nee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spleeter\\separator.py:260\u001b[0m, in \u001b[0;36mSeparator._separate_librosa\u001b[1;34m(self, waveform, audio_descriptor)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[39m# TODO: fix the logic, build sometimes return,\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39m#       sometimes set attribute.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_builder()\u001b[39m.\u001b[39moutputs\n\u001b[1;32m--> 260\u001b[0m stft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stft(waveform)\n\u001b[0;32m    261\u001b[0m \u001b[39mif\u001b[39;00m stft\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    262\u001b[0m     stft \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([stft, stft], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\18nee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spleeter\\separator.py:204\u001b[0m, in \u001b[0;36mSeparator._stft\u001b[1;34m(self, data, inverse, length)\u001b[0m\n\u001b[0;32m    201\u001b[0m out \u001b[39m=\u001b[39m []\n\u001b[0;32m    202\u001b[0m \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_channels):\n\u001b[0;32m    203\u001b[0m     d \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 204\u001b[0m         np\u001b[39m.\u001b[39;49mconcatenate((np\u001b[39m.\u001b[39;49mzeros((N,)), data[:, c], np\u001b[39m.\u001b[39;49mzeros((N,))))\n\u001b[0;32m    205\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inverse\n\u001b[0;32m    206\u001b[0m         \u001b[39melse\u001b[39;00m data[:, :, c]\u001b[39m.\u001b[39mT\n\u001b[0;32m    207\u001b[0m     )\n\u001b[0;32m    208\u001b[0m     s \u001b[39m=\u001b[39m fstft(d, hop_length\u001b[39m=\u001b[39mH, window\u001b[39m=\u001b[39mwin, center\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mwin_len_arg)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m inverse:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from utils import spleeter_utils\n",
    "# sample_audio_path = \"raw-audio/blues.00000.wav\"\n",
    "# info = spleeter_utils.separate_audio(sample_audio_path, fs=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_wav_file(accompaniment_audio, os.path.join(full_clip_dir, f'{audio_filename}_seg_test_bgnd.wav'), fs=fs,  verbose=verbose)\n",
    "# write_wav_file(vocal_audio, os.path.join(full_clip_dir, f'{audio_filename}_seg_test_voc.wav'), fs=fs,  verbose=verbose)\n",
    "# write_wav_file(full_audio, os.path.join(full_clip_dir, f'{audio_filename}_seg_test_full.wav'), fs=fs,  verbose=verbose)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
